{"cells":[{"metadata":{"_uuid":"d98e260fd46b2018f8235d76d6b46d6e149ded86"},"cell_type":"markdown","source":"# Sales Prediction\n## ( Simple Linear Regression)"},{"metadata":{"_uuid":"eb75d57ef5c0c094eb265c3fb4ef77b8f8c73dce"},"cell_type":"markdown","source":"### Problem Statement\n\nBuild a model which predicts sales based on the money spent on different platforms for marketing.\n\n### Data\nUse the advertising dataset given in ISLR and analyse the relationship between 'TV advertising' and 'sales' using a simple linear regression model. \n\nIn this notebook, we'll build a linear regression model to predict `Sales` using an appropriate predictor variable."},{"metadata":{"_uuid":"fab1024005bc13658e3ef2f8a2e46971881bc3ef"},"cell_type":"markdown","source":"## Reading and Understanding the Data"},{"metadata":{"trusted":true,"_uuid":"d68008018678c65564ddda5994cb05129f3ca72b"},"cell_type":"code","source":"# Supress Warnings\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Import the numpy and pandas package\n\nimport numpy as np\nimport pandas as pd\n\n# Data Visualisation\nimport matplotlib.pyplot as plt \nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1365d38deb407ea9c0f4e93830c5f9d4d65ebd9d"},"cell_type":"code","source":"advertising = pd.DataFrame(pd.read_csv(\"../input/advertising.csv\"))\nadvertising.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39753c6695c9c1fb90e9d0bbbba0bf8c09b600c2"},"cell_type":"markdown","source":"## Data Inspection"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"4f36948806d235d179b1a5c6b6c990a41afc6e4a"},"cell_type":"code","source":"advertising.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9578033b7d507aa4d901b48de36931066cc00241"},"cell_type":"code","source":"advertising.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b817b9601c376627448453b03d79bf8f9dd02eac"},"cell_type":"code","source":"advertising.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fab7463f8ed5eb55f1357db16c69204351295edf"},"cell_type":"markdown","source":"## Data Cleaning"},{"metadata":{"trusted":true,"_uuid":"cf9580e58b78c0558d96f54272701b6d2d32a018"},"cell_type":"code","source":"# Checking Null values\nadvertising.isnull().sum()*100/advertising.shape[0]\n# There are no NULL values in the dataset, hence it is clean.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c427a8e8a84e617eccdeda7df5eccd25f740f25d"},"cell_type":"code","source":"# Outlier Analysis\nfig, axs = plt.subplots(3, figsize = (5,5))\nplt1 = sns.boxplot(advertising['TV'], ax = axs[0])\nplt2 = sns.boxplot(advertising['Newspaper'], ax = axs[1])\nplt3 = sns.boxplot(advertising['Radio'], ax = axs[2])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f18bb0cc6014b12746f45ea30a7b769a59ad1a4"},"cell_type":"code","source":"# There are no considerable outliers present in the data.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"81898c048d2b70a32615965535f9b7a6fdc626ae"},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{"_uuid":"d2ac5e56f61c3c9517621ad569068bbdcd65b8dd"},"cell_type":"markdown","source":"### Univariate Analysis"},{"metadata":{"_uuid":"7ebb232846d9ae796b258eb26642ef73ca2dcacc"},"cell_type":"markdown","source":"#### Sales (Target Variable)"},{"metadata":{"trusted":true,"_uuid":"d435bd318677f7a4234bf02efdf54aa19e8b2c16"},"cell_type":"code","source":"sns.boxplot(advertising['Sales'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d6f716ebe182a58f9941c059256a09cc7f03703"},"cell_type":"code","source":"# Let's see how Sales are related with other variables using scatter plot.\nsns.pairplot(advertising, x_vars=['TV', 'Newspaper', 'Radio'], y_vars='Sales', height=4, aspect=1, kind='scatter')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea27ea99e47d578866a706f437d74a8fe1ad2264"},"cell_type":"code","source":"# Let's see the correlation between different variables.\nsns.heatmap(advertising.corr(), cmap=\"YlGnBu\", annot = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de3f5b90d0b6165958efcf1a31b80141867987fe"},"cell_type":"markdown","source":"As is visible from the pairplot and the heatmap, the variable `TV` seems to be most correlated with `Sales`. So let's go ahead and perform simple linear regression using `TV` as our feature variable."},{"metadata":{"_uuid":"1c10d5d48b611a9c66e1c99e66c44f6b36191a92"},"cell_type":"markdown","source":"## Model Building"},{"metadata":{"_uuid":"6d593021918853ea7402f5efa6348425481dd538"},"cell_type":"markdown","source":"### Performing Simple Linear Regression"},{"metadata":{"_uuid":"596550475e9050e4413572b184f66ddf74764878"},"cell_type":"markdown","source":"Equation of linear regression<br>\n$y = c + m_1x_1 + m_2x_2 + ... + m_nx_n$\n\n-  $y$ is the response\n-  $c$ is the intercept\n-  $m_1$ is the coefficient for the first feature\n-  $m_n$ is the coefficient for the nth feature<br>\n\nIn our case:\n\n$y = c + m_1 \\times TV$\n\nThe $m$ values are called the model **coefficients** or **model parameters**.\n\n---"},{"metadata":{"_uuid":"fe62b625cb69b757c37930b85ffc1b4b4805f4ca"},"cell_type":"markdown","source":"### Generic Steps in model building using `statsmodels`\n\nWe first assign the feature variable, `TV`, in this case, to the variable `X` and the response variable, `Sales`, to the variable `y`."},{"metadata":{"trusted":true,"_uuid":"ae7285c79fd678fad0ee4fb18f8923daf024838b"},"cell_type":"code","source":"X = advertising['TV']\ny = advertising['Sales']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b3d9b88574b3b83dd47e7e0425c8e627443c4ec3"},"cell_type":"markdown","source":"#### Train-Test Split\n\nYou now need to split our variable into training and testing sets. You'll perform this by importing `train_test_split` from the `sklearn.model_selection` library. It is usually a good practice to keep 70% of the data in your train dataset and the rest 30% in your test dataset"},{"metadata":{"trusted":true,"_uuid":"997311202075aaa98631ef95c1a0d91cdbefa2af"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, test_size = 0.3, random_state = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07e568ebfdb6c838568e2df3dfd5fd0acadc7184"},"cell_type":"code","source":"# Let's now take a look at the train dataset\n\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"873156cc1e983a63bfea8b5947bfb91e6992a7f5"},"cell_type":"code","source":"y_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a53ec07eb3235dca5ca72cc9c2f6ca0634a33a09"},"cell_type":"markdown","source":"#### Building a Linear Model\n\nYou first need to import the `statsmodel.api` library using which you'll perform the linear regression."},{"metadata":{"trusted":true,"_uuid":"226e3704ff6b78a47273fd816009f9c30b8f0a81"},"cell_type":"code","source":"import statsmodels.api as sm","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7aace406b025306a7ba85016b8bd48ae662d1ec1"},"cell_type":"markdown","source":"By default, the `statsmodels` library fits a line on the dataset which passes through the origin. But in order to have an intercept, you need to manually use the `add_constant` attribute of `statsmodels`. And once you've added the constant to your `X_train` dataset, you can go ahead and fit a regression line using the `OLS` (Ordinary Least Squares) attribute of `statsmodels` as shown below"},{"metadata":{"trusted":true,"_uuid":"b80a766082e6c9c40c3f09499fec4cfc51f62763"},"cell_type":"code","source":"# Add a constant to get an intercept\nX_train_sm = sm.add_constant(X_train)\n\n# Fit the resgression line using 'OLS'\nlr = sm.OLS(y_train, X_train_sm).fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd4287b550d2f05555ae3e18d6f497912424f8cf"},"cell_type":"code","source":"# Print the parameters, i.e. the intercept and the slope of the regression line fitted\nlr.params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f841995801587a25a9b4c4b77ef396e538e9ad1f"},"cell_type":"code","source":"# Performing a summary operation lists out all the different parameters of the regression line fitted\nprint(lr.summary())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b4184f39c773af135644179ad6f86e9e75c3d7d5"},"cell_type":"markdown","source":"####  Looking at some key statistics from the summary"},{"metadata":{"_uuid":"2eb6f1c6f44cf4b216aaf184ef64be7358c12bb7"},"cell_type":"markdown","source":"The values we are concerned with are - \n1. The coefficients and significance (p-values)\n2. R-squared\n3. F statistic and its significance"},{"metadata":{"_uuid":"5c4fab83c0633fef6b7d7c164056f58e7bf6fedf"},"cell_type":"markdown","source":"##### 1. The coefficient for TV is 0.054, with a very low p value\nThe coefficient is statistically significant. So the association is not purely by chance. "},{"metadata":{"_uuid":"78f7b40f9e278a5261b382665b3e953524aeced3"},"cell_type":"markdown","source":"##### 2. R - squared is 0.816\nMeaning that 81.6% of the variance in `Sales` is explained by `TV`\n\nThis is a decent R-squared value."},{"metadata":{"_uuid":"6f0cc01ea96a792ef1c9e369a67f5cf4949cda42"},"cell_type":"markdown","source":"###### 3. F statistic has a very low p value (practically low)\nMeaning that the model fit is statistically significant, and the explained variance isn't purely by chance."},{"metadata":{"_uuid":"355241eda62e0f3fb9b843256640d56ab6bf7fd1"},"cell_type":"markdown","source":"---\nThe fit is significant. Let's visualize how well the model fit the data.\n\nFrom the parameters that we get, our linear regression equation becomes:\n\n$ Sales = 6.948 + 0.054 \\times TV $"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"6e0dc97a88b9fc1d4e975c2fe511e59bd0cd2b8a"},"cell_type":"code","source":"plt.scatter(X_train, y_train)\nplt.plot(X_train, 6.948 + 0.054*X_train, 'r')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b0127acdc8615bb40259e313f1d91e263091ce5c"},"cell_type":"markdown","source":"## Model Evaluation"},{"metadata":{"_uuid":"422b3bc53bfd16e1583f66456a3997a53e60d4d7"},"cell_type":"markdown","source":"### Residual analysis \nTo validate assumptions of the model, and hence the reliability for inference"},{"metadata":{"_uuid":"90fd70d36d73f8756d85b91132b7783fca68de51"},"cell_type":"markdown","source":"#### Distribution of the error terms\nWe need to check if the error terms are also normally distributed (which is infact, one of the major assumptions of linear regression), let us plot the histogram of the error terms and see what it looks like."},{"metadata":{"trusted":true,"_uuid":"4dd8f2238cf72ced822605fc50ceedc3451ef5af"},"cell_type":"code","source":"y_train_pred = lr.predict(X_train_sm)\nres = (y_train - y_train_pred)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"14e47df1dd16feb210ba45abe9bd16e583dacd88"},"cell_type":"code","source":"fig = plt.figure()\nsns.distplot(res, bins = 15)\nfig.suptitle('Error Terms', fontsize = 15)                  # Plot heading \nplt.xlabel('y_train - y_train_pred', fontsize = 15)         # X-label\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e4ee1c8edba5205ff0fb2d282f3cb04d3578d40e"},"cell_type":"markdown","source":"The residuals are following the normally distributed with a mean 0. All good!"},{"metadata":{"_uuid":"21220e799147c77afe520b1eaf29664fca414fb5"},"cell_type":"markdown","source":"#### Looking for patterns in the residuals"},{"metadata":{"trusted":true,"_uuid":"9273cbc44826c16c959a63707862371c9ff4301d"},"cell_type":"code","source":"plt.scatter(X_train,res)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b9b369334a8ce91ef15c05de37b463b2df53fd1"},"cell_type":"markdown","source":"We are confident that the model fit isn't by chance, and has decent predictive power. The normality of residual terms allows some inference on the coefficients.\n\nAlthough, the variance of residuals increasing with X indicates that there is significant variation that this model is unable to explain."},{"metadata":{"_uuid":"a9f1c4e7245673932e604b4aa3a5cac748809d3d"},"cell_type":"markdown","source":"As you can see, the regression line is a pretty good fit to the data"},{"metadata":{"_uuid":"70d9188db6c5b404c66c0a1bc2b9002a86121318"},"cell_type":"markdown","source":"### Predictions on the Test Set"},{"metadata":{"_uuid":"a88d571a4e726470bb1af84b6197e7065bcd23d4"},"cell_type":"markdown","source":"Now that you have fitted a regression line on your train dataset, it's time to make some predictions on the test data. For this, you first need to add a constant to the `X_test` data like you did for `X_train` and then you can simply go on and predict the y values corresponding to `X_test` using the `predict` attribute of the fitted regression line."},{"metadata":{"trusted":true,"_uuid":"f0bed7ce820292dceee1c3b00b9ecbcb9fdbbd37"},"cell_type":"code","source":"# Add a constant to X_test\nX_test_sm = sm.add_constant(X_test)\n\n# Predict the y values corresponding to X_test_sm\ny_pred = lr.predict(X_test_sm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b64c5e3173c685b0715a93f0a77c759e90b2dff"},"cell_type":"code","source":"y_pred.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f67e3bf11f1ab0670339d4496a4b42df11d1b0cf"},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d4c698357ac5a9b1dc5e82862c081a2843e8c2b"},"cell_type":"markdown","source":"##### Looking at the RMSE"},{"metadata":{"trusted":true,"_uuid":"58863bc73dfa751e6bade66b3b71f80be51d9ca6"},"cell_type":"code","source":"#Returns the mean squared error; we'll take a square root\nnp.sqrt(mean_squared_error(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab9e84c7ccf6d83fd215ba8771cb0243a59bc88e"},"cell_type":"markdown","source":"###### Checking the R-squared on the test set"},{"metadata":{"trusted":true,"_uuid":"6ce19fc28741a4d2b558a377f2fd39c81abdb72e"},"cell_type":"code","source":"r_squared = r2_score(y_test, y_pred)\nr_squared","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"743c7b8425082fbb0a6811f2405fb7a4c1fa5a1f"},"cell_type":"markdown","source":"##### Visualizing the fit on the test set"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"eb08ac34d4e148e3221adfe126072f108adbfa24"},"cell_type":"code","source":"plt.scatter(X_test, y_test)\nplt.plot(X_test, 6.948 + 0.054 * X_test, 'r')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}