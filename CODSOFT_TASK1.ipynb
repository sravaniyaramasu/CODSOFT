{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-09-06T17:22:20.733124Z","iopub.execute_input":"2023-09-06T17:22:20.733536Z","iopub.status.idle":"2023-09-06T17:22:22.861116Z","shell.execute_reply.started":"2023-09-06T17:22:20.733503Z","shell.execute_reply":"2023-09-06T17:22:22.859744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## • Funtions","metadata":{}},{"cell_type":"code","source":"def histogram_rep(df,col_name, total_rows,x_label, x_labels, title, figsize):\n    numeric_data = pd.to_numeric(df[col_name], errors='coerce')\n    nan_count = numeric_data.isnull().sum()\n    percentage_non_numeric = (nan_count / total_rows) * 100\n    print(f\"Percentage of non-numerical values in the '{col_name}' column: {percentage_non_numeric:.2f}%\")\n\n    # Get unique values in the 'previous' column\n    unique_values = df[col_name].unique()\n    print(\"Unique values in '{col_name}' column:\")\n    \n    # Calculate the percentage of each unique value\n    percentage_values = []\n    for value in unique_values:\n        count = (df[col_name] == value).sum()\n        percentage = (count / total_rows) * 100\n        percentage_values.append(percentage)\n        print(f\"Value: {value}, Percentage: {percentage:.2f}%\")\n        \n    # Create a histogram\n    plt.figure(figsize=figsize)\n    plt.bar(unique_values, percentage_values)\n    plt.xlabel(x_label)\n    plt.ylabel('Percentage')\n    plt.title(title)\n    plt.xticks(unique_values, x_labels)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:22.863397Z","iopub.execute_input":"2023-09-06T17:22:22.863946Z","iopub.status.idle":"2023-09-06T17:22:22.875452Z","shell.execute_reply.started":"2023-09-06T17:22:22.863911Z","shell.execute_reply":"2023-09-06T17:22:22.873993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def survival_percentage(data, column_name):\n    unique_values = data[column_name].unique()\n    \n    percentages = {}\n    \n    for value in unique_values:\n        subset = data[data[column_name] == value]\n        survived_count = subset[\"Survived\"].sum()\n        total_count = len(subset)\n        if total_count > 0:\n            percentage = (survived_count / total_count) * 100\n            percentages[value] = percentage\n    \n    return percentages\n","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:22.877386Z","iopub.execute_input":"2023-09-06T17:22:22.879549Z","iopub.status.idle":"2023-09-06T17:22:22.894943Z","shell.execute_reply.started":"2023-09-06T17:22:22.879504Z","shell.execute_reply":"2023-09-06T17:22:22.893963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def survival_percentage_continuous(data, column_name, num_bins=None, bin_labels=None):\n    if num_bins is None:\n        num_bins = 10  # Default number of bins if not specified\n    \n    if bin_labels is None:\n        bin_labels = [f'Bin {i+1}' for i in range(num_bins)]  # Default bin labels\n    \n    # Create bins for the specified column\n    data['bins'] = pd.cut(data[column_name], bins=num_bins, labels=bin_labels)\n    \n    # Calculate survival percentages for each bin\n    bin_percentages = {}\n    \n    for bin_label in bin_labels:\n        subset = data[data['bins'] == bin_label]\n        survived_count = subset['Survived'].sum()\n        total_count = len(subset)\n        \n        if total_count > 0:\n            percentage = (survived_count / total_count) * 100\n            bin_percentages[bin_label] = percentage\n    \n    # Remove the 'bins' column from the DataFrame (optional)\n    data.drop(columns=['bins'], inplace=True)\n    \n    # Create a bar chart to visualize the survival percentages\n    plt.figure(figsize=(10, 6))\n    plt.bar(bin_percentages.keys(), bin_percentages.values(), color='skyblue')\n    plt.xlabel('Bins')\n    plt.ylabel('Survival Percentage (%)')\n    plt.title(f'Survival Percentage by {column_name}')\n    plt.xticks(rotation=45)\n    plt.grid(axis='y')\n    plt.show()\n    \n    return bin_percentages","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:22.898020Z","iopub.execute_input":"2023-09-06T17:22:22.898803Z","iopub.status.idle":"2023-09-06T17:22:22.916703Z","shell.execute_reply.started":"2023-09-06T17:22:22.898757Z","shell.execute_reply":"2023-09-06T17:22:22.915377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def draw_pie_chart(percentages):\n    labels = percentages.keys()\n    sizes = list(percentages.values())  # Convert dict_values to a list\n    \n    # Generate a list of shades of blue based on the number of categories\n    num_categories = len(labels)\n    colors = plt.cm.Blues(np.linspace(0.1, 1, num_categories))\n    \n    plt.figure(figsize=(8, 6))  # Adjust the figure size as needed\n    plt.pie(sizes, labels=None, colors=colors, autopct=lambda p: f'{p:.1f}%' if p > 0 else '', startangle=140)\n    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n    plt.title('Survival Percentage by Category')\n    \n    # Add custom legend\n    legend_labels = [f'{label} ({sizes[i]:.1f}%)' for i, label in enumerate(labels) if sizes[i] > 0]\n    plt.legend(legend_labels, loc='best')\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:22.918048Z","iopub.execute_input":"2023-09-06T17:22:22.918458Z","iopub.status.idle":"2023-09-06T17:22:22.930824Z","shell.execute_reply.started":"2023-09-06T17:22:22.918427Z","shell.execute_reply":"2023-09-06T17:22:22.929659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_between(s, first, last):\n    try:\n        start = s.index( first ) + len( first )\n        end = s.index( last, start )\n        return s[start:end]\n    except ValueError:\n        return \"\"","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:22.932563Z","iopub.execute_input":"2023-09-06T17:22:22.933778Z","iopub.status.idle":"2023-09-06T17:22:22.948889Z","shell.execute_reply.started":"2023-09-06T17:22:22.933734Z","shell.execute_reply":"2023-09-06T17:22:22.947922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def percent(col_name, total_rows):\n    numeric_data = pd.to_numeric(df[col_name], errors='coerce')\n    nan_count = numeric_data.isnull().sum()\n    percentage_non_numeric = (nan_count / total_rows) * 100\n    print(f\"Percentage of non-numerical values in the '{col_name}' column: {percentage_non_numeric:.2f}%\")\n\n    # Get unique values in the 'previous' column\n    unique_values = df[col_name].unique()\n    print(\"Unique values in '{col_name}' column:\")\n    \n    # Calculate the percentage of each unique value\n    percentage_values = []\n    for value in unique_values:\n        count = (df[col_name] == value).sum()\n        percentage = (count / total_rows) * 100\n        percentage_values.append(percentage)\n        print(f\"Value: {value}, Percentage: {percentage:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:22.950614Z","iopub.execute_input":"2023-09-06T17:22:22.951076Z","iopub.status.idle":"2023-09-06T17:22:22.962041Z","shell.execute_reply.started":"2023-09-06T17:22:22.951035Z","shell.execute_reply":"2023-09-06T17:22:22.961178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_null_percentage(dataframe):\n    # Calculate the total number of rows in the DataFrame\n    total_rows = len(dataframe)\n    \n    # Calculate the percentage of null values for each feature\n    null_percentage = (dataframe.isnull().sum() / total_rows) * 100\n    \n    return null_percentage","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:22.963526Z","iopub.execute_input":"2023-09-06T17:22:22.964333Z","iopub.status.idle":"2023-09-06T17:22:22.975251Z","shell.execute_reply.started":"2023-09-06T17:22:22.964269Z","shell.execute_reply":"2023-09-06T17:22:22.974024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a function to extract the ticket category\ndef extract_ticket_category(ticket):\n    if pd.isna(ticket):\n        return None\n    elif ' ' in ticket:\n        return ticket.split(' ')[0]\n    else:\n        return 'Normal'","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:22.976886Z","iopub.execute_input":"2023-09-06T17:22:22.977348Z","iopub.status.idle":"2023-09-06T17:22:22.999176Z","shell.execute_reply.started":"2023-09-06T17:22:22.977306Z","shell.execute_reply":"2023-09-06T17:22:22.998299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fill_null_with_mode(dataframe, column_name):\n    # Calculate the mode of the column\n    mode_value = dataframe[column_name].mode().iloc[0]\n    \n    # Fill null values with the mode\n    dataframe[column_name].fillna(mode_value, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:23.004752Z","iopub.execute_input":"2023-09-06T17:22:23.006189Z","iopub.status.idle":"2023-09-06T17:22:23.013407Z","shell.execute_reply.started":"2023-09-06T17:22:23.006148Z","shell.execute_reply":"2023-09-06T17:22:23.012178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read the dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/test-file/tested.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:23.014852Z","iopub.execute_input":"2023-09-06T17:22:23.015818Z","iopub.status.idle":"2023-09-06T17:22:23.067066Z","shell.execute_reply.started":"2023-09-06T17:22:23.015775Z","shell.execute_reply":"2023-09-06T17:22:23.066094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# • Data Visualization & Pre-processing","metadata":{}},{"cell_type":"code","source":"print(df.head)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:23.068358Z","iopub.execute_input":"2023-09-06T17:22:23.068873Z","iopub.status.idle":"2023-09-06T17:22:23.101237Z","shell.execute_reply.started":"2023-09-06T17:22:23.068843Z","shell.execute_reply":"2023-09-06T17:22:23.100217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:23.102589Z","iopub.execute_input":"2023-09-06T17:22:23.103135Z","iopub.status.idle":"2023-09-06T17:22:23.144303Z","shell.execute_reply.started":"2023-09-06T17:22:23.103106Z","shell.execute_reply":"2023-09-06T17:22:23.143388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.info)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:23.145572Z","iopub.execute_input":"2023-09-06T17:22:23.146065Z","iopub.status.idle":"2023-09-06T17:22:23.160992Z","shell.execute_reply.started":"2023-09-06T17:22:23.146037Z","shell.execute_reply":"2023-09-06T17:22:23.159341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = ['Pclass','Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked','Survived']\nnull_percentage = get_null_percentage(df[features])\n\n# Print the null percentage for each feature\nprint(\"Percentage of null values for each feature:\")\nprint(null_percentage,\"%\")","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:23.162704Z","iopub.execute_input":"2023-09-06T17:22:23.163593Z","iopub.status.idle":"2023-09-06T17:22:23.178381Z","shell.execute_reply.started":"2023-09-06T17:22:23.163558Z","shell.execute_reply":"2023-09-06T17:22:23.176860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(columns=['Cabin'], inplace=True)\ndf.drop(columns=['Age'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:23.180138Z","iopub.execute_input":"2023-09-06T17:22:23.180769Z","iopub.status.idle":"2023-09-06T17:22:23.190891Z","shell.execute_reply.started":"2023-09-06T17:22:23.180734Z","shell.execute_reply":"2023-09-06T17:22:23.189369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove 'Cabin' and 'Age' from the features list in one line\nfeatures = [feature for feature in features if feature not in ['Cabin', 'Age']]\n\n# Print the updated features list\nprint(features)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:23.193239Z","iopub.execute_input":"2023-09-06T17:22:23.193806Z","iopub.status.idle":"2023-09-06T17:22:23.205086Z","shell.execute_reply.started":"2023-09-06T17:22:23.193714Z","shell.execute_reply":"2023-09-06T17:22:23.204193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1) Sex","metadata":{}},{"cell_type":"code","source":"sex_result = survival_percentage(df, \"Sex\")\n\nfor key, value in sex_result.items():\n    print(f\"precentage of {key} who survived: {value:.2f}%\")\n    \ndraw_pie_chart(sex_result)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:23.206669Z","iopub.execute_input":"2023-09-06T17:22:23.207262Z","iopub.status.idle":"2023-09-06T17:22:23.486720Z","shell.execute_reply.started":"2023-09-06T17:22:23.207231Z","shell.execute_reply":"2023-09-06T17:22:23.485090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thearfore, included","metadata":{}},{"cell_type":"markdown","source":"### 2) Name --> Title","metadata":{}},{"cell_type":"code","source":"df['Title'] = df.apply(lambda row: find_between(row['Name'], \", \", \".\"), axis=1)\nfeatures.append('Title')\ndf.drop(columns=['Name'], inplace=True)\nprint(df['Title'])","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:23.489175Z","iopub.execute_input":"2023-09-06T17:22:23.490961Z","iopub.status.idle":"2023-09-06T17:22:23.509437Z","shell.execute_reply.started":"2023-09-06T17:22:23.490892Z","shell.execute_reply":"2023-09-06T17:22:23.508025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove 'Name' from the features list\nfeatures.remove('Name')\n\n# Print the updated features list\nprint(features)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:23.511087Z","iopub.execute_input":"2023-09-06T17:22:23.511566Z","iopub.status.idle":"2023-09-06T17:22:23.525932Z","shell.execute_reply.started":"2023-09-06T17:22:23.511502Z","shell.execute_reply":"2023-09-06T17:22:23.524027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col_name = 'Title'\nx_label = 'Title'\ntitle = 'Titles percentages'\nfigsize = (9, 3)\nx_labels = ['Mr', 'Mrs', 'Miss','Master','Ms','Col', 'Rev', 'Dr', 'Dona']\n\nhistogram_rep(df,col_name, len(df), x_label, x_labels, title, figsize)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:23.527549Z","iopub.execute_input":"2023-09-06T17:22:23.527891Z","iopub.status.idle":"2023-09-06T17:22:23.791018Z","shell.execute_reply.started":"2023-09-06T17:22:23.527862Z","shell.execute_reply":"2023-09-06T17:22:23.789784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"title_result = survival_percentage(df, \"Title\")\n\nfor key, value in title_result.items():\n    print(f\"precentage of {key} who survived: {value:.2f}%\")\n    \ndraw_pie_chart(title_result)        #others?????","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:23.793391Z","iopub.execute_input":"2023-09-06T17:22:23.794632Z","iopub.status.idle":"2023-09-06T17:22:24.045453Z","shell.execute_reply.started":"2023-09-06T17:22:23.794587Z","shell.execute_reply":"2023-09-06T17:22:24.044181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Same as all 'female' survived in 'Sex' column\n##### So, this column won't be useful in our prediction\n##### Therefore, not included","metadata":{}},{"cell_type":"code","source":"df.drop(columns=['Title'], inplace=True)\nfeatures.remove('Title')\nprint(features)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:24.047205Z","iopub.execute_input":"2023-09-06T17:22:24.048523Z","iopub.status.idle":"2023-09-06T17:22:24.057533Z","shell.execute_reply.started":"2023-09-06T17:22:24.048475Z","shell.execute_reply":"2023-09-06T17:22:24.055853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:24.060263Z","iopub.execute_input":"2023-09-06T17:22:24.061086Z","iopub.status.idle":"2023-09-06T17:22:24.084534Z","shell.execute_reply.started":"2023-09-06T17:22:24.061037Z","shell.execute_reply":"2023-09-06T17:22:24.083346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3) Embarked","metadata":{}},{"cell_type":"code","source":"col_name = 'Embarked'\nx_label = 'Embarked'\nx_labels = ['Q','S','C']\ntitle = 'Embarked percentage'\nfigsize = (3,3)\n\nhistogram_rep(df,col_name, len(df),x_label, x_labels, title, figsize)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:24.086240Z","iopub.execute_input":"2023-09-06T17:22:24.087163Z","iopub.status.idle":"2023-09-06T17:22:24.284022Z","shell.execute_reply.started":"2023-09-06T17:22:24.087092Z","shell.execute_reply":"2023-09-06T17:22:24.282682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embarked_result = survival_percentage(df, \"Embarked\")\n\nfor key, value in embarked_result.items():\n    print(f\"precentage of {key} who survived: {value:.2f}%\")\n    \ndraw_pie_chart(embarked_result)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:24.285696Z","iopub.execute_input":"2023-09-06T17:22:24.286128Z","iopub.status.idle":"2023-09-06T17:22:24.519613Z","shell.execute_reply.started":"2023-09-06T17:22:24.286097Z","shell.execute_reply":"2023-09-06T17:22:24.518460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4) Pclass","metadata":{}},{"cell_type":"code","source":"col_name = 'Pclass'\nx_label = 'Pclass'\nx_labels = ['3rd class', '2nd class', '1st class']\ntitle = 'Percentage of Pclass'\nfigsize = (3,4)\n\nhistogram_rep(df,col_name, len(df),x_label, x_labels, title, figsize)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:24.521097Z","iopub.execute_input":"2023-09-06T17:22:24.522167Z","iopub.status.idle":"2023-09-06T17:22:24.714800Z","shell.execute_reply.started":"2023-09-06T17:22:24.522128Z","shell.execute_reply":"2023-09-06T17:22:24.713373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embarked_result = survival_percentage(df, \"Pclass\")\n\nfor key, value in embarked_result.items():\n    print(f\"precentage of {key} who survived: {value:.2f}%\")\n    \ndraw_pie_chart(embarked_result)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:24.723462Z","iopub.execute_input":"2023-09-06T17:22:24.723862Z","iopub.status.idle":"2023-09-06T17:22:24.907192Z","shell.execute_reply.started":"2023-09-06T17:22:24.723832Z","shell.execute_reply":"2023-09-06T17:22:24.906331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5) SibSp","metadata":{}},{"cell_type":"code","source":"col_name = 'SibSp'\nx_label = 'SibSp'\ntitle = 'SibSp percentages'\nfigsize = (4, 3)\nx_labels = ['0','1','2','3','4','5','8']\n\nhistogram_rep(df,col_name, len(df), x_label, x_labels, title, figsize)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:24.908274Z","iopub.execute_input":"2023-09-06T17:22:24.908901Z","iopub.status.idle":"2023-09-06T17:22:25.222697Z","shell.execute_reply.started":"2023-09-06T17:22:24.908874Z","shell.execute_reply":"2023-09-06T17:22:25.221390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SibSp_result = survival_percentage(df, \"SibSp\")\n\nfor key, value in SibSp_result.items():\n    print(f\"precentage of {key} who survived: {value:.2f}%\")\n    \ndraw_pie_chart(SibSp_result)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:25.224076Z","iopub.execute_input":"2023-09-06T17:22:25.224435Z","iopub.status.idle":"2023-09-06T17:22:25.559594Z","shell.execute_reply.started":"2023-09-06T17:22:25.224405Z","shell.execute_reply":"2023-09-06T17:22:25.558387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6) Parch","metadata":{}},{"cell_type":"code","source":"col_name = 'Parch'\nx_label = 'Parch'\ntitle = 'Parch percentages'\nfigsize = (9, 3)\nx_labels = ['0', '1', '3', '2', '4', '6','5','9']      # 8 classes\n\nhistogram_rep(df,col_name, len(df), x_label, x_labels, title, figsize)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:25.561107Z","iopub.execute_input":"2023-09-06T17:22:25.561793Z","iopub.status.idle":"2023-09-06T17:22:25.859685Z","shell.execute_reply.started":"2023-09-06T17:22:25.561758Z","shell.execute_reply":"2023-09-06T17:22:25.858355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Parch_result = survival_percentage(df, \"Parch\")\n\nfor key, value in Parch_result.items():\n    print(f\"precentage of {key} who survived: {value:.2f}%\")\n    \ndraw_pie_chart(Parch_result)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:25.861311Z","iopub.execute_input":"2023-09-06T17:22:25.861973Z","iopub.status.idle":"2023-09-06T17:22:26.205148Z","shell.execute_reply.started":"2023-09-06T17:22:25.861938Z","shell.execute_reply":"2023-09-06T17:22:26.204225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7) Ticket","metadata":{}},{"cell_type":"code","source":"# Split the 'Ticket' column and store the first part in 'Ticket_category'\ndf['Ticket_category'] = df['Ticket'].str.split(' ').str[0]","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:26.206529Z","iopub.execute_input":"2023-09-06T17:22:26.207137Z","iopub.status.idle":"2023-09-06T17:22:26.216571Z","shell.execute_reply.started":"2023-09-06T17:22:26.207099Z","shell.execute_reply":"2023-09-06T17:22:26.215155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col_name = 'Ticket'\ndf['Ticket_category'] = df[col_name].apply(extract_ticket_category)\npercent('Ticket_category', len(df))","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:26.217759Z","iopub.execute_input":"2023-09-06T17:22:26.218154Z","iopub.status.idle":"2023-09-06T17:22:26.249791Z","shell.execute_reply.started":"2023-09-06T17:22:26.218122Z","shell.execute_reply":"2023-09-06T17:22:26.248849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(columns=['Ticket'], inplace=True)\nfeatures.remove('Ticket')\nfeatures.append('Ticket_category')\nprint(features)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:26.251566Z","iopub.execute_input":"2023-09-06T17:22:26.252002Z","iopub.status.idle":"2023-09-06T17:22:26.377726Z","shell.execute_reply.started":"2023-09-06T17:22:26.251973Z","shell.execute_reply":"2023-09-06T17:22:26.376599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the count of each ticket category\nticket_category_counts = df['Ticket_category'].value_counts()\n\n# Extract unique categories and their counts\ncategories = ticket_category_counts.index\ncounts = ticket_category_counts.values\n\n# Create a scatter plot\nplt.figure(figsize=(18, 6))\nplt.scatter(categories, counts, c='blue', marker='o')\nplt.xlabel('Ticket Category')\nplt.ylabel('Count')\nplt.title('Ticket Category Distribution')\nplt.xticks(rotation=45)\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:26.379592Z","iopub.execute_input":"2023-09-06T17:22:26.380082Z","iopub.status.idle":"2023-09-06T17:22:26.947140Z","shell.execute_reply.started":"2023-09-06T17:22:26.380039Z","shell.execute_reply":"2023-09-06T17:22:26.945403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### So, there is an outlier","metadata":{}},{"cell_type":"code","source":"df.drop(columns=['Ticket_category'], inplace=True)\nfeatures.remove('Ticket_category')\nprint(features)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:26.948951Z","iopub.execute_input":"2023-09-06T17:22:26.949693Z","iopub.status.idle":"2023-09-06T17:22:26.958368Z","shell.execute_reply.started":"2023-09-06T17:22:26.949650Z","shell.execute_reply":"2023-09-06T17:22:26.957205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8) Fare: A numerical variable for the price of the ticket.","metadata":{}},{"cell_type":"code","source":"col_name = 'Fare'\npercent(col_name, len(df))\nsns.kdeplot(data=df['Fare'], color='red')","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:26.959850Z","iopub.execute_input":"2023-09-06T17:22:26.961261Z","iopub.status.idle":"2023-09-06T17:22:27.384848Z","shell.execute_reply.started":"2023-09-06T17:22:26.961214Z","shell.execute_reply":"2023-09-06T17:22:27.383578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### • pre-processing","metadata":{}},{"cell_type":"code","source":"print(df.head)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.386350Z","iopub.execute_input":"2023-09-06T17:22:27.386714Z","iopub.status.idle":"2023-09-06T17:22:27.399940Z","shell.execute_reply.started":"2023-09-06T17:22:27.386686Z","shell.execute_reply":"2023-09-06T17:22:27.398347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Now, there is non-numerical values\n#####    To remove them we should use linear regression and predict its values from other columns\n##### Or simply drop it","metadata":{}},{"cell_type":"code","source":"# Define the features to use for prediction\n#use_features = ['Pclass', 'Sex_female', 'Sex_male', 'SibSp', 'Parch', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n\n# Filter the DataFrame to only include rows with non-null 'Fare' values\n#df_clean = df.dropna(subset=['Fare'])\n\n# Create the feature matrix X and target variable y\n#X = df_clean[use_features]\n#y = df_clean['Fare']\n\n# Create and fit the linear regression model\n#model = LinearRegression()\n#model.fit(X, y)\n\n# Filter the DataFrame to only include rows with null 'Fare' values\n#null_fare_indices = df[df['Fare'].isnull()].index\n\n# Predict missing 'Fare' values using the model\n#predicted_fares = model.predict(df.loc[null_fare_indices, use_features])\n\n# Fill the null 'Fare' values with the predicted values\n#df.loc[null_fare_indices, 'Fare'] = predicted_fares","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.401890Z","iopub.execute_input":"2023-09-06T17:22:27.402236Z","iopub.status.idle":"2023-09-06T17:22:27.413137Z","shell.execute_reply.started":"2023-09-06T17:22:27.402208Z","shell.execute_reply":"2023-09-06T17:22:27.411464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#col_name = 'Fare'\n#percent(col_name, len(df))\n#sns.kdeplot(data=df['Fare'], color='red')","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.415101Z","iopub.execute_input":"2023-09-06T17:22:27.415656Z","iopub.status.idle":"2023-09-06T17:22:27.431044Z","shell.execute_reply.started":"2023-09-06T17:22:27.415613Z","shell.execute_reply":"2023-09-06T17:22:27.429949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(columns=['Fare'], inplace=True)\nfeatures.remove('Fare')\nprint(features)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.432725Z","iopub.execute_input":"2023-09-06T17:22:27.433085Z","iopub.status.idle":"2023-09-06T17:22:27.449361Z","shell.execute_reply.started":"2023-09-06T17:22:27.433051Z","shell.execute_reply":"2023-09-06T17:22:27.447780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.head)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.450655Z","iopub.execute_input":"2023-09-06T17:22:27.451057Z","iopub.status.idle":"2023-09-06T17:22:27.473296Z","shell.execute_reply.started":"2023-09-06T17:22:27.451025Z","shell.execute_reply":"2023-09-06T17:22:27.471792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 9) Embarked: Alphanumerical cabin code.","metadata":{}},{"cell_type":"code","source":"col_name = 'Embarked'\nx_label = 'Embarked'\ntitle = 'Embarked percentages'\nfigsize = (3, 3)\nx_labels = ['Q','S','C']\n\nhistogram_rep(df,col_name, len(df), x_label, x_labels, title, figsize)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.475261Z","iopub.execute_input":"2023-09-06T17:22:27.475805Z","iopub.status.idle":"2023-09-06T17:22:27.683392Z","shell.execute_reply.started":"2023-09-06T17:22:27.475758Z","shell.execute_reply":"2023-09-06T17:22:27.682163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Embarked_result = survival_percentage(df, \"Embarked\")\n\nfor key, value in Embarked_result.items():\n    print(f\"percentage of {key} who survived: {value:.2f}%\")\n\ndraw_pie_chart(Embarked_result)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.684863Z","iopub.execute_input":"2023-09-06T17:22:27.685305Z","iopub.status.idle":"2023-09-06T17:22:27.863239Z","shell.execute_reply.started":"2023-09-06T17:22:27.685250Z","shell.execute_reply":"2023-09-06T17:22:27.861423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(features)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.865622Z","iopub.execute_input":"2023-09-06T17:22:27.867482Z","iopub.status.idle":"2023-09-06T17:22:27.877108Z","shell.execute_reply.started":"2023-09-06T17:22:27.867410Z","shell.execute_reply":"2023-09-06T17:22:27.875629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"use_features = ['Pclass', 'Sex', 'SibSp', 'Parch']\ndf = pd.get_dummies(features)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.879450Z","iopub.execute_input":"2023-09-06T17:22:27.881096Z","iopub.status.idle":"2023-09-06T17:22:27.894231Z","shell.execute_reply.started":"2023-09-06T17:22:27.880962Z","shell.execute_reply":"2023-09-06T17:22:27.892667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.896619Z","iopub.execute_input":"2023-09-06T17:22:27.898355Z","iopub.status.idle":"2023-09-06T17:22:27.924127Z","shell.execute_reply.started":"2023-09-06T17:22:27.898277Z","shell.execute_reply":"2023-09-06T17:22:27.922767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df[use_features]\ny = df['Survived']","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.926035Z","iopub.execute_input":"2023-09-06T17:22:27.926680Z","iopub.status.idle":"2023-09-06T17:22:27.941996Z","shell.execute_reply.started":"2023-09-06T17:22:27.926634Z","shell.execute_reply":"2023-09-06T17:22:27.940626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.info()\ny.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.943408Z","iopub.execute_input":"2023-09-06T17:22:27.943985Z","iopub.status.idle":"2023-09-06T17:22:27.978348Z","shell.execute_reply.started":"2023-09-06T17:22:27.943954Z","shell.execute_reply":"2023-09-06T17:22:27.977408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# • Divide the data into train and test","metadata":{}},{"cell_type":"code","source":"# Split your data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.979776Z","iopub.execute_input":"2023-09-06T17:22:27.980135Z","iopub.status.idle":"2023-09-06T17:22:27.989368Z","shell.execute_reply.started":"2023-09-06T17:22:27.980104Z","shell.execute_reply":"2023-09-06T17:22:27.988097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split your data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.990716Z","iopub.execute_input":"2023-09-06T17:22:27.991094Z","iopub.status.idle":"2023-09-06T17:22:28.010501Z","shell.execute_reply.started":"2023-09-06T17:22:27.991065Z","shell.execute_reply":"2023-09-06T17:22:28.009150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create and fit the model\n#model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n#model.fit(X_train, y_train)\n\n# Make predictions on both train and test data\n#train_predictions = model.predict(X_train)\n#test_predictions = model.predict(X_test)\n\n# Calculate train and test accuracy\n#train_accuracy = accuracy_score(y_train, train_predictions)\n#test_accuracy = accuracy_score(y_test, test_predictions)\n\n# Print both train and test accuracy\n#print(f\"Train Accuracy: {train_accuracy:.2%}\")\n#print(f\"Test Accuracy: {test_accuracy:.2%}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:28.012104Z","iopub.execute_input":"2023-09-06T17:22:28.013408Z","iopub.status.idle":"2023-09-06T17:22:28.026679Z","shell.execute_reply.started":"2023-09-06T17:22:28.013369Z","shell.execute_reply":"2023-09-06T17:22:28.025233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a list of models to try\nmodels = [\n    (\"Random Forest\", RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)),\n    (\"Gradient Boosting\", GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=1)),\n    (\"Logistic Regression\", LogisticRegression(random_state=1))\n]\n\nbest_model = None\nbest_accuracy = 0.0\n\nfor model_name, model in models:\n    print(f\"Training {model_name}...\")\n    \n    train_accuracy_list = []\n    val_accuracy_list = []\n    test_accuracy_list = []\n\n    # Train the model and track accuracy\n    for epoch in range(1, 101):  # You can adjust the number of epochs\n        model.fit(X_train, y_train)\n\n        train_predictions = model.predict(X_train)\n        val_predictions = model.predict(X_val)  # Assuming you have a validation set X_val and y_val\n        test_predictions = model.predict(X_test)\n\n        train_accuracy = accuracy_score(y_train, train_predictions)\n        val_accuracy = accuracy_score(y_val, val_predictions)\n        test_accuracy = accuracy_score(y_test, test_predictions)\n\n        train_accuracy_list.append(train_accuracy)\n        val_accuracy_list.append(val_accuracy)\n        test_accuracy_list.append(test_accuracy)\n\n    # Print both train and test accuracy\n    print(f\"{model_name} Train Accuracy: {train_accuracy:.2%}\")\n    print(f\"{model_name} Validation Accuracy: {val_accuracy:.2%}\")\n    print(f\"{model_name} Test Accuracy: {test_accuracy:.2%}\")\n    print(\"\\n\")\n\n    if val_accuracy > best_accuracy:\n        best_accuracy = val_accuracy\n        best_model = model_name\n        \n# Check if all models have similar accuracy\nsimilar_models = all(val == best_accuracy for val in val_accuracy_list)\nif similar_models:\n    print(\"All models have similar performance.\")\nelse:\n    print(f\"The best model is {best_model} with a validation accuracy of {best_accuracy:.2%}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:28.028524Z","iopub.execute_input":"2023-09-06T17:22:28.029158Z","iopub.status.idle":"2023-09-06T17:22:59.964804Z","shell.execute_reply.started":"2023-09-06T17:22:28.029123Z","shell.execute_reply":"2023-09-06T17:22:59.963259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting train accuracy vs validation accuracy and train accuracy vs test accuracy\nplt.figure(figsize=(15, 5))\n\n# Train accuracy vs validation accuracy\nplt.subplot(1, 2, 1)\nplt.plot(train_accuracy_list, label='Train Accuracy', c='red')\nplt.plot(val_accuracy_list, label='Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Train Accuracy vs Validation Accuracy')\nplt.legend()\n\n# Train accuracy vs test accuracy\nplt.subplot(1, 2, 2)\nplt.plot(train_accuracy_list, label='Train Accuracy', c='red')\nplt.plot(test_accuracy_list, label='Test Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Train Accuracy vs Test Accuracy')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:59.966503Z","iopub.execute_input":"2023-09-06T17:22:59.966868Z","iopub.status.idle":"2023-09-06T17:23:00.545331Z","shell.execute_reply.started":"2023-09-06T17:22:59.966839Z","shell.execute_reply":"2023-09-06T17:23:00.544063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for model_name, model in models:\n    print(f\"Evaluating {model_name}...\")\n    \n    # Train the model\n    model.fit(X_train, y_train)\n\n    # Make predictions\n    train_predictions = model.predict(X_train)\n    val_predictions = model.predict(X_val)  # Assuming you have a validation set X_val and y_val\n    test_predictions = model.predict(X_test)\n\n    # Calculate confusion matrix and classification report for train data\n    train_cm = confusion_matrix(y_train, train_predictions)\n    train_cr = classification_report(y_train, train_predictions, output_dict=True, zero_division=1)\n    \n    # Calculate confusion matrix and classification report for validation data\n    val_cm = confusion_matrix(y_val, val_predictions)\n    val_cr = classification_report(y_val, val_predictions, output_dict=True, zero_division=1)\n\n    # Calculate confusion matrix and classification report for test data\n    test_cm = confusion_matrix(y_test, test_predictions)\n    test_cr = classification_report(y_test, test_predictions, output_dict=True, zero_division=1)\n    \n    # Display confusion matrix as a heatmap for test data\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(test_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title(f'Confusion Matrix - {model_name} (Test Data)')\n    plt.show()\n\n    # Print classification report for test data\n    print(f\"Classification Report for {model_name} - Test Data:\")\n    print(classification_report(y_test, test_predictions))","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:23:00.546853Z","iopub.execute_input":"2023-09-06T17:23:00.547189Z","iopub.status.idle":"2023-09-06T17:23:01.940297Z","shell.execute_reply.started":"2023-09-06T17:23:00.547162Z","shell.execute_reply":"2023-09-06T17:23:01.938153Z"},"trusted":true},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}